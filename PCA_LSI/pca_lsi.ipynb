{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrF8A_TGOz1D"
   },
   "source": [
    "<h1 align='center'><font size=10>PCA_LSI</h1>\n",
    "<h1 align='center'><font size=5>Zach Chase</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XQJGiRmuOz1M"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from math import log\n",
    "from scipy import sparse\n",
    "from sklearn import datasets\n",
    "from scipy import linalg as la\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import linalg as spla\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a multivariate statistical tool used to orthogonally\n",
    "change the basis of a set of observations from the basis of original features (which may be correlated)\n",
    "into a basis of uncorrelated (in fact, orthonormal) variables called the principal components. It is a\n",
    "direct application of the singular value decomposition (SVD) from linear algebra. More specifically,\n",
    "the first principal component will account for the greatest variance in the set of observations, the\n",
    "second principal component will be orthogonal to the first, accounting for the second greatest variance\n",
    "in the set of observations, etc. The first several principal components capture most of the variance in\n",
    "the observation set, and hence provide a great deal of information about the data. By projecting the\n",
    "observations onto the space spanned by the principal components, we can reduce the dimensionality\n",
    "of the data in a manner that preserves most of the variance. [<sup>1</sup>](#fn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement PCA and use on Iris dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KQ-0uAF5Oz1O"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def iris_pca():\n",
    "    \"\"\"Function that calculates PCA and applies it to the Iris dataset to find the first 2 principal components.\"\"\"\n",
    "    \n",
    "    # Load Iris Dataset\n",
    "    X, Y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "    # Calculate min of X shape (# of features)\n",
    "    k = min(X.shape)\n",
    "    \n",
    "    # Convert data to mean 0\n",
    "    X = X - X.mean(axis = 0)\n",
    "    \n",
    "    # Calculate SVD of Data\n",
    "    U, Sig, V = la.svd(X, full_matrices=False)\n",
    "    V = V.T\n",
    "    \n",
    "    # Project observations to 2 principal component space\n",
    "    Y_hat = X@V[:,:k]\n",
    "    \n",
    "    # Plot First and second principal components with accompying label\n",
    "    for i, j in zip(set(Y),[\"Setosa\", \"Versicolor\", \"Verginica\"]):\n",
    "        plt.scatter(Y_hat[:,0][Y==i], Y_hat[:,1][Y==i], label = j, s = 4)\n",
    "    plt.xlabel(\"First Component\")\n",
    "    plt.ylabel(\"Second Component\")\n",
    "    plt.suptitle(\"Iris Dataset\")\n",
    "    plt.xlim([-4,4])\n",
    "    plt.ylim([-4,4])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "iris_pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline/gridsearch on iris dataset for PCA and random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RF__max_depth': 10, 'RF__n_estimators': 50, 'robust__with_centering': True, 'robust__with_scaling': True, 'scaler__with_mean': True, 'scaler__with_std': True}\n",
      "0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "def PCA_RF():\n",
    "    '''\n",
    "    Create a pipeline and grid search to find the best combination \n",
    "    of PCA truncation and random forest classifier for the iris \n",
    "    dataset. Return the best paramters and score in a tuple. \n",
    "\n",
    "    Returns:\n",
    "    search.best_params_: A dictionary displaying the best parameter discovered from the grid search\n",
    "    search.best_score_: The mean cross-validated score with the best parameters used\n",
    "    ''' \n",
    "    \n",
    "    # Import libraries for pipeline and gridsearch\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Load dataset\n",
    "    X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "    # make a pipeline with 2+ tranformers\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                     (\"robust\", RobustScaler()),\n",
    "                     (\"RF\", RandomForestClassifier())])\n",
    "\n",
    "    # grid search on the pipeline\n",
    "    pipe_param_grid = {\"scaler__with_mean\":[True, False],\n",
    "                      \"scaler__with_std\": [True, False],\n",
    "                       \"RF__n_estimators\": [50,80,100,120,150],\n",
    "                       \"RF__max_depth\": [10,20,50,100,None],\n",
    "                      \"robust__with_centering\": [True, False],\n",
    "                      \"robust__with_scaling\": [True, False]}\n",
    "\n",
    "    pipe_gs = GridSearchCV(pipe,pipe_param_grid).fit(X, y)\n",
    "\n",
    "    # report hyperparameters of the best estimator\n",
    "    print(pipe_gs.best_params_, pipe_gs.best_score_, sep='\\n')\n",
    "    \n",
    "PCA_RF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Indexing (LSI) is an application of PCA which employs the SVD to reduce the\n",
    "dimensionality of a large corpus of text documents in order to enable us to evaluate the similarity\n",
    "between two documents. Many information-retrieval systems used in government and in industry are\n",
    "based on LSI.[<sup>2</sup>](#fn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement LSI by doing the following:\n",
    "- Create a function that takes in a sparse matrix and index and return the indices of the most similar and least similar documents\n",
    "- Create a function that converts speech documents into an n by m array\n",
    "- Create a function that applies the techniques of LSI and the above functions to a single State of the Union address speech and returns the addresses that are most and least similar to that speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_tldnDbWOz1S"
   },
   "outputs": [],
   "source": [
    "def similar(i, Xhat):\n",
    "    \"\"\"\n",
    "    Takes a document and returns the index of\n",
    "    two documents. The one that is the most similar \n",
    "    and the one that is the least similar.\n",
    "    \n",
    "    Parameters:\n",
    "    i index of a document\n",
    "    Xhat decomposed data\n",
    "    \n",
    "    Returns:\n",
    "    index_min: index of the document most similar to document i\n",
    "    index_max: index of the document least similar to document i\n",
    "    \"\"\"\n",
    "\n",
    "    #Initialize to find max and min\n",
    "    similarity_min = np.inf\n",
    "    similarity_max = -np.inf\n",
    "    index_min = 0\n",
    "    index_max = 0\n",
    "    \n",
    "    # Iterate through each row of Xhat\n",
    "    for j in range(Xhat.shape[0]):\n",
    "        \n",
    "        # Find rows not relating to the index\n",
    "        if j != i:\n",
    "            \n",
    "            # Calculate the similarity\n",
    "            numerator = np.dot(Xhat[i,:], Xhat[j,:])\n",
    "            denominator = la.norm(Xhat[i,:]) * la.norm(Xhat[j,:])\n",
    "            similarity = numerator/denominator\n",
    "            \n",
    "            # Update if new min or max\n",
    "            if similarity < similarity_min:\n",
    "                similarity_min = similarity\n",
    "                index_min = j\n",
    "            if similarity > similarity_max:\n",
    "                similarity_max = similarity\n",
    "                index_max = j\n",
    "                \n",
    "    return index_min, index_max\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7Rv2ENwdOz1T"
   },
   "outputs": [],
   "source": [
    "def document_converter():\n",
    "    '''\n",
    "    Converts speech documents into an n by m array where m is the number \n",
    "    of vocabulary words and n is the number of documents\n",
    "    \n",
    "    Returns:\n",
    "    X sparse matrix (n x m): Each row represents a document\n",
    "    paths (list): list where each element is a speech path eg: path[0] is './Addresses/1990-Bush.txt'\n",
    "    '''\n",
    "    # Get list of filepaths to each text file in the folder.\n",
    "    folder = \"./Addresses/\"\n",
    "    paths = [folder+p for p in os.listdir(folder) if p.endswith(\".txt\")]\n",
    "\n",
    "    # Helper function to get list of words in a string.\n",
    "    def extractWords(text):\n",
    "        ignore = string.punctuation + string.digits\n",
    "        cleaned = \"\".join([t for t in text.strip() if t not in ignore])\n",
    "        return cleaned.lower().split()\n",
    "\n",
    "    # Initialize vocab set, then read each file and add to the vocab set.\n",
    "    vocab = set()\n",
    "    for p in paths:\n",
    "        with open(p, 'r') as infile:\n",
    "            for line in infile:\n",
    "                vocab.update(extractWords(line)) #union sets together\n",
    "\n",
    "\n",
    "    # load stopwords\n",
    "    with open(\"stopwords.txt\", 'r') as f:\n",
    "        stops = set([w.strip().lower() for w in f.readlines()])\n",
    "\n",
    "    # remove stopwords from vocabulary, create ordering\n",
    "    vocab = {w:i for i, w in enumerate(vocab.difference(stops))}\n",
    "\n",
    "\n",
    "    counts = []      # holds the entries of X\n",
    "    doc_index = []   # holds the row index of X\n",
    "    word_index = []  # holds the column index of X\n",
    "\n",
    "    # Iterate through the documents.\n",
    "    for doc, p in enumerate(paths):\n",
    "        with open(p, 'r') as f:\n",
    "            # Create the word counter.\n",
    "            ctr = Counter()\n",
    "            for line in f:\n",
    "                ctr.update(extractWords(line))\n",
    "            # Iterate through the word counter, store counts.\n",
    "            for word, count in ctr.items():\n",
    "                if word in vocab:\n",
    "                    word_index.append(vocab[word])\n",
    "                    counts.append(count)\n",
    "                    doc_index.append(doc)\n",
    "\n",
    "    # Create sparse matrix holding these word counts.\n",
    "    X = sparse.csr_matrix((counts, [doc_index, word_index]),\n",
    "                           shape=(len(paths), len(vocab)), dtype=np.float)\n",
    "    return X, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kUKZCyteOz1V"
   },
   "outputs": [],
   "source": [
    "def LSI_speech(speech, l=7):\n",
    "    \"\"\"\n",
    "    Uses LSI, applied to the word count matrix X, with the first 7 principal\n",
    "    components to find the most similar and least similar speeches\n",
    "\n",
    "    Parameters:\n",
    "        speech str: Path to speech eg: \"./Addresses/1984-Reagan.txt\"\n",
    "        l (int): Number of principal components\n",
    "\n",
    "    Returns:\n",
    "        tuple of str: (Most similar speech, least similar speech)\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Get X and the paths\n",
    "    X, paths = document_converter()\n",
    "    k = min(X.shape)\n",
    "    \n",
    "    # Find index of specific speech\n",
    "    index = paths.index(speech)\n",
    "            \n",
    "    # Calculate Xhat\n",
    "    U, Sig, V = sparse.linalg.svds(X, k = l)\n",
    "    V = V.T\n",
    "    X_hat = U @ np.diag(Sig)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    min_similarity, max_similarity = similar(index, X_hat)\n",
    "    \n",
    "    return paths[max_similarity], paths[min_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speeches most similar and least similar to Reagan's in 1984:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/0cgy4n956v3cxdlwkj7hn7zm0000gn/T/ipykernel_29461/4151569478.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  shape=(len(paths), len(vocab)), dtype=np.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Addresses/1988-Reagan.txt', './Addresses/1946-Truman.txt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Speeches most similar and least similar to Reagan's in 1984:\")\n",
    "LSI_speech(\"./Addresses/1984-Reagan.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Application of LSI\n",
    "Note that some words are more important than others. While the above application of LSI simply compares the word usage between speeches, we will now implement a better form of LSI that gives weights to words that are more important. We will then repeat the process done above and compare State of the Union speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pYxnjgFJOz1Y"
   },
   "outputs": [],
   "source": [
    "def weighted_document_converter():\n",
    "    '''\n",
    "    Converts speech documents into an n by m array where m is the number \n",
    "    of vocabulary words and n is the number of documents. It gives weights\n",
    "    to the most important words in the vocabulary.\n",
    "    \n",
    "    Returns:\n",
    "    X sparse matrix (n x m): Each row represents a document\n",
    "    paths (list): list where each element is a speech path eg: path[0] is './Addresses/1990-Bush.txt'\n",
    "    '''\n",
    "    # Get list of filepaths to each text file in the folder.\n",
    "    folder = \"./Addresses/\"\n",
    "    paths = [folder+p for p in os.listdir(folder) if p.endswith(\".txt\")]\n",
    "\n",
    "    # Helper function to get list of words in a string.\n",
    "    def extractWords(text):\n",
    "        ignore = string.punctuation + string.digits\n",
    "        cleaned = \"\".join([t for t in text.strip() if t not in ignore])\n",
    "        return cleaned.lower().split()\n",
    "\n",
    "    # Initialize vocab set, then read each file and add to the vocab set.\n",
    "    vocab = set()\n",
    "    for p in paths:\n",
    "        with open(p, 'r') as infile:\n",
    "            for line in infile:\n",
    "                vocab.update(extractWords(line))\n",
    "\n",
    "\n",
    "    # load stopwords\n",
    "    with open(\"stopwords.txt\", 'r') as f:\n",
    "        stops = set([w.strip().lower() for w in f.readlines()])\n",
    "\n",
    "    # remove stopwords from vocabulary, create ordering\n",
    "    vocab = {w:i for i, w in enumerate(vocab.difference(stops))}\n",
    "\n",
    "    t = np.zeros(len(vocab))\n",
    "    counts = []\n",
    "    doc_index = []\n",
    "    word_index = []\n",
    "\n",
    "    # get doc-term counts and global term counts\n",
    "    for doc, path in enumerate(paths):\n",
    "        with open(path, 'r') as f:\n",
    "            # create the word counter\n",
    "            ctr = Counter()\n",
    "            for line in f:\n",
    "                words = extractWords(line)\n",
    "                ctr.update(words)\n",
    "            # iterate through the word counter, store counts\n",
    "            for word, count in ctr.items():\n",
    "                if word in vocab:\n",
    "                    word_ind = vocab[word]\n",
    "                    word_index.append(word_ind)\n",
    "                    counts.append(count)\n",
    "                    doc_index.append(doc)\n",
    "                    t[word_ind] += count\n",
    "\n",
    "    # Get global weights.\n",
    "    X = sparse.csr_matrix((counts, [doc_index, word_index]),\n",
    "                           shape=(len(paths), len(vocab)), dtype=np.float)\n",
    "\n",
    "    P = X/np.sum(X, axis = 1)\n",
    "    g = np.zeros(X.shape[1])\n",
    "    for j in range(X.shape[1]):\n",
    "        total = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            total += (P[i,j] * np.log(P[i,j] + 1))/np.log(X.shape[0])\n",
    "        g[j] = 1 + total\n",
    "    \n",
    "    A = np.zeros((X.shape))\n",
    "    \n",
    "    for j in range(X.shape[1]):\n",
    "        for i in range(X.shape[0]):\n",
    "            A[i,j] = g[j] * log(X[i,j] + 1)\n",
    "    \n",
    "    return A, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SZfoc_q_Oz1a"
   },
   "outputs": [],
   "source": [
    "def LSI_weighted(speech, l=7):\n",
    "    \"\"\"\n",
    "    Uses LSI, applied to the globally weighted word count matrix A, with the\n",
    "    first 7 principal components to find the most similar and least similar speeches\n",
    "\n",
    "    Parameters:\n",
    "        speech str: Path to speech eg: \"./Addresses/1984-Reagan.txt\"\n",
    "        l (int): Number of principal components\n",
    "\n",
    "    Returns:\n",
    "        tuple of str: (Most similar speech, least similar speech)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get X and the paths\n",
    "    X, paths = weighted_document_converter()\n",
    "    k = min(X.shape)\n",
    "    \n",
    "        \n",
    "    # Find index of specific speech\n",
    "    index = paths.index(speech)\n",
    "    \n",
    "    # Calculate Xhat using PCA from sklearn\n",
    "    pca = PCA(n_components=l)\n",
    "    X_hat = pca.fit_transform(X)\n",
    "    \n",
    "    # Use similarity function to find most and least similar\n",
    "    min_similarity, max_similarity = similar(index, X_hat)\n",
    "    \n",
    "    return paths[max_similarity], paths[min_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YnTBJ16rOz1b",
    "outputId": "76c95555-a1ec-4d7b-d457-e33a7469f09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speeches most similar and least similar to Clinton's in 1984:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/0cgy4n956v3cxdlwkj7hn7zm0000gn/T/ipykernel_29461/1313561867.py:60: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  shape=(len(paths), len(vocab)), dtype=np.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Addresses/1994-Clinton.txt', './Addresses/1951-Truman.txt')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Speeches most similar and least similar to Clinton's in 1984:\")\n",
    "LSI_weighted(\"./Addresses/1993-Clinton.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeBOl3LhOz1d"
   },
   "source": [
    "## Special Thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"fn1\"> A very special thanks to the Brigham Young University ACME program for their guidance on this project. For further details, please visit https://acme.byu.edu/00000179-afb2-d74f-a3ff-bfbb157b0001/pca19-pdf</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pca_lsi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
